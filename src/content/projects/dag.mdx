---
title: "DAG"
description: "Transforming messy design text into structured dependency graphs."
category: "thinking"
order: 2
heroImage: ""
tags: ["Information Architecture", "Graph"]
meta:
  Role: "Product Designer"
  Tools: "Figma, React, Python"
  Duration: "8 Weeks"
  Team: "Solo Project"
  Year: "2024"
---
import ProjectSection from '../../components/ProjectSection.astro';

<div slot="intro">
    <p>DAG tools help designers transform messy, unstructured design text and requirements into structured dependency graphs, enabling better visualization of complex systems.</p>
</div>

import PlaceholderImage from '../../components/PlaceholderImage.astro';

<PlaceholderImage height="500px" caption="Hero Image: Global View" />

<div slot="intro">
    <p>DAG tools help designers transform messy, unstructured design text and requirements into structured dependency graphs, enabling better visualization of complex systems.</p>
</div>

<ProjectSection title="Problem & Opportunity" id="problem-opportunity">
    <p>In complex design systems, understanding dependencies is crucial but often obscured by messy documentation. This project explores how we can transform unstructured text into clear, visual graphs to reveal hidden connections.</p>
    <PlaceholderImage height="400px" caption="Initial sketches of dependency chaos" />
</ProjectSection>

<ProjectSection title="Approach" id="approach">
    <p>The concept emerged from observing designers struggle with "dependency hell" in large projects. I began by sketching metaphors of networks and flow, looking for ways to make abstract relationships tangible.</p>
    <PlaceholderImage height="300px" />
    <p>I framed the problem as an translation challenge: converting linear, ambiguous text into spatial, deterministic nodes. This required a strict ontology for what constitutes a "dependency."</p>
    <PlaceholderImage height="250px" caption="Ontology mapping diagram" />
</ProjectSection>

<ProjectSection title="Implementation" id="implementation">
    <p>The system is built using a combination of NLP parsing and force-directed graph rendering. The core engine analyzes text for causal keywords ("depends on", "requires", "blocks") and constructs an adjacency matrix.</p>
    <div class="grid-2">
        <PlaceholderImage height="300px" />
        <PlaceholderImage height="300px" />
    </div>
</ProjectSection>

<ProjectSection title="Interaction Model/UX" id="interaction-model">
    <p>Users simply paste their documentation. The tool instantly visualizes the graph. Interactive nodes allow for filtering and "what-if" analysis, showing the ripple effects of potential changes.</p>
    <PlaceholderImage height="500px" caption="Interactive graph interface" />
</ProjectSection>

<ProjectSection title="Outcome" id="outcome">
    <p>The output is a live, navigable map of the project's logic. It highlights critical paths, circular dependencies, and orphaned requirements, giving teams immediate actionable insights.</p>
    <PlaceholderImage height="400px" />
</ProjectSection>

<ProjectSection title="Reflection" id="reflection">
    <p>I used AI not just for the final parsing, but throughout the process to simulate user data and stress-test the visualization with complex, generated scenarios. This allowed for rapid iteration on the graph physics.</p>
    <PlaceholderImage height="350px" caption="AI simulation results" />
</ProjectSection>
